{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fashion-mnist_test.csv  fashion.ipynb           t10k-labels-idx1-ubyte\n",
      "fashion-mnist_train.csv t10k-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "label_map = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD CSV DATA\n",
    "#tr_filename = 'fashion-mnist_train.csv'\n",
    "#tr = pd.read_csv(tr_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IMAGE DATA\n",
    "f = 'train-images-idx3-ubyte'\n",
    "l = 'train-labels-idx1-ubyte'\n",
    "imagearray = idx2numpy.convert_from_file(f)\n",
    "labels = idx2numpy.convert_from_file(l)\n",
    "\n",
    "tf = 't10k-images-idx3-ubyte'\n",
    "tl = 't10k-labels-idx1-ubyte'\n",
    "test_imagearray = idx2numpy.convert_from_file(tf)\n",
    "test_labels = idx2numpy.convert_from_file(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imagearray[30], cmap=plt.cm.binary)\n",
    "print(imagearray.shape)\n",
    "#print(label_map[labels[30]])\n",
    "#print(imagearray[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing, normalize data\n",
    "class Normalize:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X)\n",
    "        self.std = np.std(X)\n",
    "        \n",
    "    def normalize(self, X):\n",
    "        X -= self.mean\n",
    "        X /= self.std\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = imagearray.copy()\n",
    "lbls = labels.copy()\n",
    "test_imgs = test_imagearray.copy()\n",
    "test_lbls = test_labels.copy()\n",
    "\n",
    "imgs.flags.writeable = True\n",
    "imgs = imgs.astype(np.float64)\n",
    "test_imgs.flags.writeable = True\n",
    "test_imgs = test_imgs.astype(np.float64)\n",
    "\n",
    "scale = Normalize()\n",
    "scale.fit(imgs)\n",
    "\n",
    "imgs = scale.normalize(imgs)\n",
    "test_imgs = scale.normalize(test_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81713d3c50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAANMElEQVR4nO3db6hc9Z3H8c/Ha+KfNEhibiSa4K0lyIaVTeoQFlyKIhb1SdIHXZsHJQtKChpooQ9Wug/qQ5FtS4USSDU0K11rsRUjyG4lBKSIxTFEE427Ubnb5g+5Ey6aVNSY5NsH91hu451zxpkzc2b9vl8wzMz5zpnzvXPv587M+Z2ZnyNCAL74Lmm6AQCjQdiBJAg7kARhB5Ig7EASl45yYytWrIipqalRbhJIZXp6WqdOnfJCtYHCbvtOST+VNCHpsYh4uOz2U1NTarfbg2wSQIlWq9W11vfLeNsTkn4m6S5J6yRtsb2u3/sDMFyDvGffKOntiHg3Is5K+pWkTfW0BaBug4T9Okl/mnf9aLHsb9jeZrttu93pdAbYHIBBDBL2hXYCfObY24jYGRGtiGhNTk4OsDkAgxgk7EclrZl3fbWk44O1A2BYBgn7K5LW2v6y7cWSviVpTz1tAahb30NvEXHO9nZJ/625obddEfFGbZ0BqNVA4+wR8byk52vqBcAQcbgskARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IImBpmy2PS3pjKTzks5FRKuOpgDUb6CwF26LiFM13A+AIeJlPJDEoGEPSb+z/artbQvdwPY2223b7U6nM+DmAPRr0LDfEhFflXSXpAdsf+3iG0TEzohoRURrcnJywM0B6NdAYY+I48X5jKRnJG2soykA9es77LaX2F766WVJX5d0qK7GANRrkL3x10h6xvan9/OfEfFftXQFoHZ9hz0i3pX0DzX2AmCIGHoDkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJFEZdtu7bM/YPjRv2XLbL9g+UpwvG26bAAbVyzP7LyTdedGyByXtjYi1kvYW1wGMscqwR8SLkmYvWrxJ0u7i8m5Jm+ttC0Dd+n3Pfk1EnJCk4nxltxva3ma7bbvd6XT63ByAQQ19B11E7IyIVkS0Jicnh705AF30G/aTtldJUnE+U19LAIah37DvkbS1uLxV0rP1tANgWC6tuoHtJyXdKmmF7aOSfijpYUm/tn2vpD9K+uYwm/z/7sCBA6X1t956q7R+ww03lNbXrFnTtbZ48eLSda+++urS+jBFRGnd9og6yaEy7BGxpUvp9pp7ATBEHEEHJEHYgSQIO5AEYQeSIOxAEpV74+sUETp37lzX+sTExNC2PegwzoYNG/q+7/vuu6+0/tJLL5XW33///dJ62ZGJZ8+eLV33ww8/LK1v3LixtL558+bS+o033ti1VvW4XbhwobT+RR2aG9bPxTM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiQx0nF227r00pFusmdPP/10ab1s7HP//v0Dbfv+++8vrVd9FPTll1/uWnvnnXdK173qqqtK6zMz5d9L8thjj5XWb7rppq61e+65p3Tdyy67rLT+RVX1+646/qAbntmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAlXjenVad26dfHEE090rVeNqy5b1v9ksVU/Z9nXMUvS9PR019r1119fum7ZZ/glDfXYg/fee6+0vmPHjtL62rVrS+u33XZbaf3QoUNda6+99lrpups2bSqtVz3uGbVaLbXb7QUPCuGZHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSGOmHy2dnZ/XUU091re/bt690/TvuuKNr7dprry1dd8mSJaX17du3l9bLplWuGi+uGmevqld9j/ipU6e61s6cOdP3upJ08uTJ0vqbb75ZWj9y5EjX2unTp0vXPX78eGn99tvLJxL++OOPu9YWLVpUum6n0+n7vqXq3+kVV1zRtfbJJ5+Urlv2HQEffPBB11rlM7vtXbZnbB+at+wh28dsHyhOd1fdD4Bm9fIy/heS7lxg+U8iYn1xer7etgDUrTLsEfGipNkR9AJgiAbZQbfd9uvFy/yuB63b3ma7bbtdNa8YgOHpN+w7JH1F0npJJyT9qNsNI2JnRLQiolW2UwLAcPUV9og4GRHnI+KCpJ9LKp/qE0Dj+gq77VXzrn5DUvfPMQIYC5Xj7LaflHSrpBW2j0r6oaRbba+XFJKmJX2nl42tXr1ajzzySNf6o48+Wrr+c88917VWNV58ySXl/9eqxuEPHjzYtbZ06dLSdY8dO1Zan5qaKq33+z3hvaxbNX97Vb3qewI++uijrrWq4weqPos/yPENVduuqlf9PVV9R8GVV17ZtVb1dnflypVda2U/c2XYI2LLAosfr1oPwHjhcFkgCcIOJEHYgSQIO5AEYQeSGOlXSbdarWi320O576qPFFYN08zOlh/+X/ZRz6ohoqrezp8/X1qfmJgorZcNE1X9fsuGcaTqYcWqKZ+XL1/etXb55ZeXrls1fFX1uJXdf9XQ2eLFi0vrVR+RrRo+q1q/X3yVNADCDmRB2IEkCDuQBGEHkiDsQBKEHUhipF8lPUxVY7I333zziDoBxhPP7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSqAy77TW299k+bPsN298tli+3/YLtI8X5suG3C6BfvTyzn5P0/Yj4O0n/KOkB2+skPShpb0SslbS3uA5gTFWGPSJORMT+4vIZSYclXSdpk6Tdxc12S9o8pB4B1OBzvWe3PSVpg6Q/SLomIk5Ic/8QJC04aZjtbbbbttudTmfAdgH0q+ew2/6SpN9I+l5EnO51vYjYGRGtiGhNTk720yOAGvQUdtuLNBf0X0bEb4vFJ22vKuqrJM0Mp0UAdehlb7wlPS7pcET8eF5pj6StxeWtkp6tvz0Adenle+NvkfRtSQdtHyiW/UDSw5J+bfteSX+U9M2hdAigFpVhj4jfS1pwcndJt9fbDoBh4Qg6IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuhlfvY1tvfZPmz7DdvfLZY/ZPuY7QPF6e7htwugX73Mz35O0vcjYr/tpZJetf1CUftJRPz78NoDUJde5mc/IelEcfmM7cOSrht2YwDq9bnes9uekrRB0h+KRdttv257l+1lXdbZZrttu93pdAbrFkDfeg677S9J+o2k70XEaUk7JH1F0nrNPfP/aKH1ImJnRLQiojU5OTl4xwD60lPYbS/SXNB/GRG/laSIOBkR5yPigqSfS9o4vDYBDKqXvfGW9LikwxHx43nLV8272TckHaq/PQB16WVv/C2Svi3poO0DxbIfSNpie72kkDQt6TtD6A9ATXrZG/97SV6g9Hz97QAYFo6gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGIGN3G7I6k/5u3aIWkUyNr4PMZ197GtS+J3vpVZ2/XR8SC3/820rB/ZuN2OyJajTVQYlx7G9e+JHrr16h642U8kARhB5JoOuw7G95+mXHtbVz7kuitXyPprdH37ABGp+lndgAjQtiBJBoJu+07bf+P7bdtP9hED93YnrZ9sJiGut1wL7tsz9g+NG/Zctsv2D5SnC84x15DvY3FNN4l04w3+tg1Pf35yN+z256Q9L+S7pB0VNIrkrZExJsjbaQL29OSWhHR+AEYtr8m6c+S/iMi/r5Y9oik2Yh4uPhHuSwi/nVMentI0p+bnsa7mK1o1fxpxiVtlvQvavCxK+nrnzWCx62JZ/aNkt6OiHcj4qykX0na1EAfYy8iXpQ0e9HiTZJ2F5d3a+6PZeS69DYWIuJEROwvLp+R9Ok0440+diV9jUQTYb9O0p/mXT+q8ZrvPST9zvartrc13cwCromIE9LcH4+klQ33c7HKabxH6aJpxsfmsetn+vNBNRH2haaSGqfxv1si4quS7pL0QPFyFb3paRrvUVlgmvGx0O/054NqIuxHJa2Zd321pOMN9LGgiDhenM9IekbjNxX1yU9n0C3OZxru56/GaRrvhaYZ1xg8dk1Of95E2F+RtNb2l20vlvQtSXsa6OMzbC8pdpzI9hJJX9f4TUW9R9LW4vJWSc822MvfGJdpvLtNM66GH7vGpz+PiJGfJN2tuT3y70j6tyZ66NLXDZJeK05vNN2bpCc197LuE829IrpX0tWS9ko6UpwvH6PenpB0UNLrmgvWqoZ6+yfNvTV8XdKB4nR3049dSV8jedw4XBZIgiPogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJvwCTGSuKSgXmoAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(imgs[30], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data into training and validation sets\n",
    "def train_val_split(X, y, percent=85):\n",
    "    percent = float(percent)\n",
    "    if(percent > 1): \n",
    "        percent = percent/100\n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    idxs = np.random.permutation(y.shape[0])\n",
    "    i = int(percent*y.shape[0])\n",
    "    train_X, train_y = X[0: i], y[0: i]\n",
    "    val_X, val_y = X[i:], y[i:]\n",
    "    return train_X, train_y, val_X, val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, val_X, val_y = train_val_split(imgs, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all hyperparameters here\n",
    "hyperparams = {\n",
    "    'batch_size': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_epochs': 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data loaders to cooperate with torch training loop\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))\n",
    "val_dataset = torch.utils.data.TensorDataset(torch.from_numpy(val_X), torch.from_numpy(val_y))\n",
    "tr_loader = torch.utils.data.DataLoader(train_dataset, batch_size=hyperparams['batch_size'], shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=hyperparams['batch_size'], shuffle=False)\n",
    "\n",
    "#Do we need to define a Dataset & DataLoader for the test dataset?\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.from_numpy(test_imgs), torch.from_numpy(test_lbls))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define CNN architecture\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 5, 5, 2)\n",
    "        self.conv2 = nn.Conv2d(5, 50, 5, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1250, 100)\n",
    "        self.fc1 = nn.Linear(100, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #Conv layer 1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        \n",
    "        #Conv layer 2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        #Flatten\n",
    "        x = x.view(-1, 1250)\n",
    "        \n",
    "        #Fully connected 1\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        #Fully connected 2\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        #Fully connected 3, (does not apply softmax... yet)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "#Apply softmax to get predicted label\n",
    "def predict(network_output):\n",
    "    \n",
    "    assert network_output.shape[1] == 10\n",
    "    \n",
    "    pred = F.softmax(network_output, 1)\n",
    "    \n",
    "    return torch.argmax(pred, dim=1)\n",
    "\n",
    "#Load and save model funcs from state_dict\n",
    "def save(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    \n",
    "def load(path, eval_mode = False):\n",
    "    model = CNN()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    if eval_mode:\n",
    "        model.eval()   \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in range(hyperparam['num_epochs']):\n",
    "    \n",
    "    #Evaluate training batch\n",
    "    for i, X, y in enumerate(tr_loader):\n",
    "        \n",
    "        #Zero out gradients\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        \n",
    "        #Forward pass of training batch\n",
    "        output = model(X)\n",
    "        \n",
    "        #Compute loss of batch\n",
    "        loss = criterion(output, y)\n",
    "        \n",
    "        #Calculate gradients (backprop)\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters (ADAM)\n",
    "        optimizer.step()\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    #Evaluate training AND validation accuracy && loss\n",
    "    y_true, y_pred = [], []\n",
    "    correct, total = 0.0, 0.0\n",
    "    running_loss = []\n",
    "    \n",
    "    for X, y in tr_loader:\n",
    "        with torch.no_grad():\n",
    "            output = Model(X)\n",
    "            preds = predict(output)\n",
    "            \n",
    "            y_true.append(y)\n",
    "            y_pred.append(preds)\n",
    "            \n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            running_loss.append(criterion(output, y).item())\n",
    "    \n",
    "    train_loss.append(np.mean(running_loss))\n",
    "    train_acc.append(correct/total)\n",
    "    \n",
    "    y_true, y_pred = [], []\n",
    "    correct, total = 0.0, 0.0\n",
    "    running_loss = []\n",
    "    for X, y in val_loader:\n",
    "        with torch.no_grad():\n",
    "            output = Model(X)\n",
    "            preds = predict(output)\n",
    "            \n",
    "            y_true.append(y)\n",
    "            y_pred.append(preds)\n",
    "            \n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            \n",
    "            running_loss.append(criterion(output, y).item())\n",
    "    \n",
    "    val_loss.append(np.mean(running_loss))\n",
    "    val_acc.append(correct/total)\n",
    "    \n",
    "    #Save model\n",
    "    save(model, f'eo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
